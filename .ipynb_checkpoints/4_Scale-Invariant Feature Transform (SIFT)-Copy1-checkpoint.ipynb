{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Invariant Feature Detector\n",
    "by Robinson Garcia\n",
    "\n",
    "sources:\n",
    "\n",
    "\n",
    "Ref: https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\n",
    "Ref: https://www.dropbox.com/sh/26xgy96py8itk14/AABhgCbYzraeSMkDpjY92kFVa/Lecture%20slides?dl=0&preview=2017f.Week10.Topic15.lecture.sift.pdf&subfolder_nav_tracking=1\n",
    "Ref: https://cs.nyu.edu/~fergus/teaching/vision_2012/3_Corners_Blobs_Descriptors.pdf\n",
    "Ref: https://arxiv.org/pdf/1603.09114.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''python libraries'''\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "'''The following alternative cythonized functions where implemented to improve performance'''\n",
    "import src.c.patches3 as cpy_patches3\n",
    "import src.c.nn as cpy_nn\n",
    "import src.c.GaussianFilter as cpy_GF\n",
    "import src.c.feature_aux as cpy_features\n",
    "import src.c.im2col as cpy_im2col\n",
    "import src.c.descriptor as cpy_desc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extractor:\n",
    "\n",
    "## Image processing / filtering / gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def GaussianFilter(w,h,sigma):\n",
    "    m = (w-1)/2\n",
    "    n = (h-1)/2\n",
    "    G = []\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            G.append(math.e**(-1*((i-m)**2+(j-n)**2)/(2*sigma**2)))\n",
    "\n",
    "    return np.array(G).reshape(w,h)/np.sum(np.array(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand_stack(im_stack,size):\n",
    "    N,H,W = im_stack.shape\n",
    "    _,h,w = size\n",
    "    factor = int(H/h)\n",
    "    base=np.zeros((N,h,w))\n",
    "    i = np.arange(H)*factor\n",
    "    j = np.arange(W)*factor\n",
    "    j = np.repeat(j[np.newaxis,:],H,axis=0)\n",
    "    i = np.repeat(i[:,np.newaxis],W,axis=1)\n",
    "    print(i.shape,j.shape)\n",
    "    print(base.shape)\n",
    "    base[:,i,j] = im_stack\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''Using cythonized code\n",
    "def get_im2col_indices_blur(x_shape, field_height, field_width, p_x=1,p_y=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * p_x - field_height) % stride == 0\n",
    "    assert (W + 2 * p_y - field_height) % stride == 0\n",
    "    out_height = int((H + 2 * p_x - field_height) / stride + 1)\n",
    "    out_width = int((W + 2 * p_y - field_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k, i, j)\n",
    "\n",
    "\n",
    "def conv_octave(im,g,stride=1,C=3):\n",
    "    im = im[:,np.newaxis,:,:]\n",
    "    N,_,H,W = im.shape\n",
    "    _,h,w = g.shape\n",
    "    \n",
    "    stride=1\n",
    "    h_pad = int((H*(stride-1)-stride+h)/2)\n",
    "    w_pad = int((W*(stride-1)-stride+w)/2)\n",
    "\n",
    "    \n",
    "    cols = cpy_im2col.im2col_cython(im, h, w, h_pad,stride)\n",
    "      \n",
    "    k,i,j = get_im2col_indices_blur((N,1,H,W), h, w, p_x=h_pad,p_y=w_pad, stride=1)\n",
    "\n",
    "    #im_padded = np.pad(im,((0,0),(0,0),(h_pad,h_pad),(w_pad,w_pad)),'mean')\n",
    "    #cols = im_padded[:,k,i,j]\n",
    "    \n",
    "\n",
    "    g = g.reshape((N,-1))\n",
    "\n",
    "    \n",
    "    sol = np.squeeze(np.matmul(g[:,np.newaxis,:],cols))\n",
    "    \n",
    "    return sol.reshape(N,H,W)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_octave_cython(im,g,stride=1,C=3):\n",
    "    im = im[:,np.newaxis,:,:]\n",
    "\n",
    "    N,_,H,W = im.shape\n",
    "    _,h,w = g.shape\n",
    "\n",
    "    h_pad = int((H*(stride-1)-stride+h)/2)\n",
    "    w_pad = int((W*(stride-1)-stride+w)/2)\n",
    "\n",
    "    ii = np.zeros((N,H*W))\n",
    "    for t,i in enumerate(im):\n",
    "        img = i[np.newaxis,:,:]\n",
    "        cols = cpy_im2col.im2col_cython(img, h, w, h_pad,stride)\n",
    "        gg = g[t].flatten()\n",
    "        ii[t]=np.matmul(cols.T,gg)\n",
    "    return ii.reshape(-1,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stack(sig0,s,h,w):\n",
    "    k = 2**(1/s)\n",
    "    sigma = np.power(k,np.arange(s+1))*sig0\n",
    "    g = []\n",
    "    for std in sigma:\n",
    "        g.append(cpy_GF.GaussianFilter(h,w,std))\n",
    "    return np.stack(g),sigma\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyramid of DOG images:\n",
    "$$D(x,y,\\rho) = I(x,y)*(G(x,y,k\\rho) - G(x,y,\\rho))$$\n",
    "for $$\\rho=\\sigma.k\\sigma,k^2\\sigma,...,k^{s-1}\\sigma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_zero2one(M):\n",
    "    \n",
    "    min_ = M.min()\n",
    "    max_ = M.max()\n",
    "    M = (M-min_)/(max_-min_)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octave(im_stack,factor,sig0=1.6,s=5,h=3,w=3):\n",
    "    g,sigma = filter_stack(sig0,s,h,w)\n",
    "    s1 = np.array([[0,1,0],[0,0,0],[0,-1,0]])\n",
    "    s2 = np.repeat(s1.T[np.newaxis,:,:],s+1,axis=0)\n",
    "    s1 = np.repeat(s1[np.newaxis,:,:],s+1,axis=0)\n",
    "    \n",
    "    L = conv_octave_cython(Reduce_stack(im_stack,factor),g)\n",
    "    L = scale_zero2one(L)\n",
    "    #print('Reduced shape: {}'.format(L.shape))\n",
    "    \n",
    "    D = L[1:s+1] - L[0:s]\n",
    "    \n",
    "    L_gradx = conv_octave_cython(L,s2)\n",
    "    L_grady = conv_octave_cython(L,s1)\n",
    "    #plt.imshow(L_gradx[0,:,:],**{'cmap':'gray'})\n",
    "    #plt.show()\n",
    "    #plt.imshow(L_grady[0,:,:],**{'cmap':'gray'})\n",
    "    #plt.show()\n",
    "    #plt.imshow(D[0,:,:],**{'cmap':'gray'})\n",
    "    #plt.show()\n",
    "\n",
    "    return D,L,sigma,(L_gradx,L_grady)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.c.hist as cpy_hist\n",
    "def set_rho(Lgrad,xk,h,w):\n",
    "    \n",
    "    Lgradx,Lgrady = Lgrad\n",
    "    Lmod =np.sqrt(Lgradx**2+Lgrady**2)\n",
    "    Lrho = np.arctan2(Lgrady,Lgradx)\n",
    "    Lrho[Lrho<0]+=2*math.pi\n",
    "    Lmod = cpy_patches3.get_patches3(Lmod,xk,h,w)\n",
    "    Lrho = cpy_patches3.get_patches3(Lrho,xk,h,w)\n",
    "    bins = np.arange(0,2*math.pi+math.pi/36,2*math.pi/36)\n",
    "    hist = cpy_hist.histogram(Lmod.reshape((Lmod.shape[0],-1)),\n",
    "                                   Lrho.reshape((Lrho.shape[0],-1)),\n",
    "                                   bins,xk,8)\n",
    "    \n",
    "    mod = np.sum(hist**2,axis=1)[:,np.newaxis]\n",
    "    hist=np.divide(hist,mod,out=np.zeros_like(hist),where=mod!=0)\n",
    "    idx = np.argmax(hist,axis=1)\n",
    "    rho = bins[idx]\n",
    "                       \n",
    "    return np.vstack((xk.T,rho)).T\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "Using cythonized function instead\n",
    "def get_patches3(D,xk,h=3,w=3):\n",
    "\n",
    "    N,H,W = D.shape\n",
    "\n",
    "    stride=1\n",
    "\n",
    "    h_pad = int((H*(stride-1)-stride+h)/2)\n",
    "    w_pad = int((W*(stride-1)-stride+w)/2)\n",
    "    \n",
    "    \n",
    "    h_ = int((h-1)/2)\n",
    "    w_ = int((w-1)/2)\n",
    "    #shape_=(3,3)\n",
    "    patches=[]\n",
    "    D_padded = np.pad(D,((0,0),(h_pad,h_pad),(w_pad,w_pad)),'constant')\n",
    "\n",
    "    for f in range(xk.shape[0]):\n",
    "        i,j,k,_= xk[f].astype(int)\n",
    "        \n",
    "        i+=h_pad\n",
    "        j+=w_pad\n",
    "        patches.append(D_padded[k,i-h_:i+h_+1,j-w_:j+w_+1])\n",
    "        shape = D_padded[k,i-h_:i+h_+1,j-w_:j+w_+1].shape\n",
    "        if np.sum(shape)==0:\n",
    "            print(shape,i,j,k)\n",
    "            print('check get patches function')\n",
    "\n",
    "    return np.stack(patches)\n",
    "'''     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting DOG extrema\n",
    "\n",
    "Find all pixels that correspond to extrema of $D(x,y,\\rho)$. For each $(x,y,\\rho)$, check wether $D(x,y,\\rho)$ is greater than (or smaller than) all of its neighbours in current scale and adjacent scales above & below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im2col_indices_conv2d_max(x_shape, field_height, field_width, p_x=1,p_y=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * p_x - field_height) % stride == 0\n",
    "    assert (W + 2 * p_y - field_height) % stride == 0\n",
    "    out_height = int((H + 2 * p_x - field_height) / stride + 1)\n",
    "    out_width = int((W + 2 * p_y - field_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k, i, j)\n",
    "\n",
    "def conv2d_max(f,g,k=1,**kwargs):\n",
    "    #f = f[:,np.newaxis,:,:]\n",
    "    #f = np.repeat(f,3,axis=1)\n",
    "\n",
    "    N,H,W=f.shape\n",
    "\n",
    "    n = np.tile(np.arange(3),N-2) + np.repeat(np.arange(N-2),3)\n",
    "    f = f[n,:,:].reshape((N-2,3,H,W))\n",
    "\n",
    "    N,C,H,W = f.shape\n",
    "    h,w = g\n",
    "\n",
    "    x_pad = int(0.5*((W-1)*1-W+w))\n",
    "    y_pad = int(0.5*((H-1)*1-H+w))\n",
    "\n",
    "    f_pad = np.pad(f,((0,0),(0,0),(x_pad,x_pad),(y_pad,y_pad)),mode='maximum')\n",
    "\n",
    "    k,i,j = get_im2col_indices_conv2d_max((N,C,H,W), h, w, p_x=x_pad,p_y=y_pad, stride=1)\n",
    "\n",
    "    cols = f_pad[:,k,i,j]\n",
    "\n",
    "    xc = int((h*w-1)/2)\n",
    "    cols = np.delete(cols,(xc,xc+h*w,xc+2*h*w),1)\n",
    "\n",
    "    cond = ((f[:,1,:,:].flatten() >\n",
    "             np.max(cols,axis=1).flatten())|(f[:,1,:,:].flatten() <\n",
    "                                   np.min(cols,axis=1).flatten()))\n",
    "\n",
    "    return np.moveaxis(cond.reshape(N,H,W),0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining location of Extrema\n",
    "2nd order taylor expansion of D at $(x,y,\\rho)$:\n",
    "$$D\\left(\\Delta\\vec{x}^{\\,}\\right) = D(\\vec{x}^{\\,}) +\\left(\\frac{\\partial D}{\\partial \\vec{x}^{\\,}}\\right)^T\\Delta\\vec{x}^{\\,} + \\frac{1}{2}\\left(\\Delta\\vec{x}^{\\,}\\right)^T\\frac{\\partial^2 D}{\\partial \\vec{x}^{\\,2}}\\left(\\Delta\\vec{x}^{\\,}\\right)$$\n",
    "Gradient wrt $\\Delta\\vec{x}^{\\,}$:\n",
    "$$\\frac{\\partial D}{\\partial \\Delta\\vec{x}^{\\,} } = \\left(\\frac{\\partial D}{\\partial \\vec{x}^{\\,}}\\right) + \\frac{\\partial^2 D}{\\partial \\vec{x}^{\\,2}}\\left(\\Delta\\vec{x}^{\\,}\\right)$$\n",
    "Minimum occurs when $\\frac{\\partial D}{\\partial \\Delta\\vec{x}^{\\,} }=0$\n",
    "$$\\Delta\\vec{x}^{\\,}  = - \\left(\\frac{\\partial^2 D}{\\partial \\vec{x}^{\\,2}}^{-1}\\right)\\left(\\frac{\\partial D}{\\partial \\vec{x}^{\\,}}\\right)$$\n",
    "\n",
    "All gradients estimated using finite differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute new locations and prune insignificant extrema:\n",
    "\n",
    "Find the Hessian for each key point and prune if $\\frac{Tr^2(H)}{Det(H)}>(1.1)^2$.\n",
    "\n",
    "Look for Harris Corner detector to understand this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint orientation assignment\n",
    " Contribution to the bin is: $$\\left|\\nabla I(x,y)\\right|G_{1.5\\rho_i}(d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sig(xk,sigma):\n",
    "    sig = np.zeros(xk.shape[0])\n",
    "    k=0\n",
    "    for i in xk:\n",
    "        sig[k] = sigma[i[2]]\n",
    "        k+=1\n",
    "    return np.vstack((xk.T,sig)).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG(L_grad,xk,h=9,w=9):\n",
    "    Lx,Ly = L_grad\n",
    "    Lmod = np.sqrt(Lx**2+Ly**2)\n",
    "    rho = np.arctan2(Ly,Lx)\n",
    "    rho[rho<0]+=2*math.pi\n",
    "    Lmod_patches = cpy_patches3.get_patches3(Lmod,xk,h,w)\n",
    "    rho_patches = cpy_patches3.get_patches3(rho,xk,h,w)\n",
    "    return Lmod_patches,rho_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris2(D,xk,edge_th):\n",
    "    \n",
    "    #gx = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "    gy = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "    gx = gy.T\n",
    "    gx = np.repeat(gx[np.newaxis,:,:],D.shape[0],axis=0)\n",
    "    gy = np.repeat(gy[np.newaxis,:,:],D.shape[0],axis=0)\n",
    "\n",
    "    D2grad_x = conv_octave_cython(D,gx)\n",
    "    D2grad_y = conv_octave_cython(D,gy)\n",
    "\n",
    "    Dxx = np.sum(cpy_patches3.get_patches3(D2grad_x,xk),axis=(1,2))\n",
    "    Dyy = np.sum(cpy_patches3.get_patches3(D2grad_y,xk),axis=(1,2))\n",
    "\n",
    "    H = np.array([[Dxx**2,Dxx*Dyy],[Dxx*Dyy,Dyy**2]])\n",
    "\n",
    "    tr = np.trace(H)**2\n",
    "    det = np.linalg.det(np.moveaxis(H,2,0))\n",
    "\n",
    "    #R = det - 0.04*tr\n",
    "    return np.divide(tr,det,out=np.zeros_like(tr),where=det!=0)<((edge_th+1)/10)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deriv(pyr,kp):\n",
    "    pyr = np.moveaxis(pyr,0,2)\n",
    "\n",
    "    z = kp[:,2].astype(int)\n",
    "    y = kp[:,1].astype(int)+1\n",
    "    x = kp[:,0].astype(int)+1\n",
    "\n",
    "\n",
    "    pyr = np.pad(pyr,((1,1),(1,1),(0,0)),'maximum')\n",
    "\n",
    "    Ix = pyr[x+1,y,z] - pyr[x-1,y,z]\n",
    "    Iy = pyr[x,y+1,z] - pyr[x,y-1,z]\n",
    "    Is = pyr[x,y,z+1] - pyr[x,y,z-1]\n",
    "    Ixy = pyr[x+1,y+1,z] - pyr[x-1,y-1,z]\n",
    "\n",
    "    #H = np.array([[Ix,Ixy],[Ixy,Iy]])\n",
    "\n",
    "    Ixx = pyr[x+1,y,z] - 2*pyr[x,y,z] + pyr[x-1,y,z]\n",
    "    Iyy = pyr[x,y+1,z] - 2*pyr[x,y,z] + pyr[x,y-1,z]\n",
    "    Iss = pyr[x,y,z+1] - 2*pyr[x,y,z] + pyr[x,y,z-1]\n",
    "    Ixxyy = pyr[x+1,y+1,z] - 2*pyr[x,y,z] + pyr[x-1,y-1,z]\n",
    "    Ixxss = pyr[x+1,y,z+1] - 2*pyr[x,y,z] + pyr[x-1,y,z-1]\n",
    "    Iyyss = pyr[x,y+1,z+1] - 2*pyr[x,y,z] + pyr[x,y-1,z-1]\n",
    "\n",
    "    H = np.array([[Ixx,Ixxyy,Ixxss],[Ixxyy,Iyy,Iyyss],[Ixxss,Iyyss,Iss]])\n",
    "    J = np.array([[Ix**2,Ix*Iy],[Ix*Iy,Iy**2]])\n",
    "    dx = np.array([Ix,Iy,Is])\n",
    "    return H,dx,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refine_location_prune(im,D,kp,peak_th=0.03,edge_th=10,debug=False):\n",
    "    D = D**2\n",
    "    #D = (D-D.min())/(D.max()-D.min())\n",
    "    \n",
    "    H,dx,J = get_deriv(D,kp)\n",
    "\n",
    "    U,S,V = np.linalg.svd(np.moveaxis(H,2,0))\n",
    "    S = S[:,:,np.newaxis]*np.diag(np.ones(3))\n",
    "    A = np.linalg.inv(S)\n",
    "    H_inv = np.matmul(-np.matmul(A,S),V)\n",
    "    deltas = np.squeeze(np.matmul(H_inv,np.moveaxis(dx,1,0)[:,:,np.newaxis]))\n",
    "    #deltas=np.round(deltas)\n",
    "\n",
    "    xk=kp\n",
    "    D[xk[:,2].astype(int),xk[:,0].astype(int),xk[:,1].astype(int)]+=0.5*np.sum(dx.T*deltas,axis=1)\n",
    "\n",
    "    Ds = D[xk[:,2].astype(int),xk[:,0].astype(int),xk[:,1].astype(int)]\n",
    "    Ds = (Ds-Ds.min())/(Ds.max()-Ds.min())\n",
    "    if debug==True: print('Maximum contrast: {}'.format(Ds.max()))\n",
    "    if debug==True: print('Minimum contrast: {}'.format(Ds.min()))\n",
    "    if debug==True: print('Average contrast: {}'.format(Ds.mean()))\n",
    "    cond1 = Ds > peak_th\n",
    "    if debug==True: print(\"Number of kps removed after th: {}\".format(np.sum(~cond1)))\n",
    "    #if kp.shape[1]!=0:\n",
    "    cond2 = harris2(D,kp,edge_th)\n",
    "    if debug==True: print(\"Number of kps removed edge extraction: {}\".format(np.sum(~cond2)))\n",
    "\n",
    "    keep = ((cond2) & (cond1))\n",
    "    return (deltas,keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "def features(L_grad,xk,ilum_sat=0.2):\n",
    "    N = xk.shape[0]\n",
    "    Lx,Ly = L_grad\n",
    "    Lmod = np.sqrt(Lx**2+Ly**2)\n",
    "    rho = np.arctan2(Ly,Lx)\n",
    "    rho[rho<0]+=2*math.pi\n",
    "    \n",
    "    fks = cpy_desc.build_fk(Lmod,rho,xk,block_size=16,cell_size=4,nBins=8)\n",
    "    \n",
    "    mod = np.sqrt(np.sum(fks**2,axis=1))[:,np.newaxis]\n",
    "    fks = np.divide(fks,mod,out=np.zeros_like(fks),where=mod!=0)\n",
    "    fks = np.clip(fks,a_min=None,a_max=ilum_sat)\n",
    "    mod = np.sqrt(np.sum(fks**2,axis=1))[:,np.newaxis]\n",
    "    fks = np.divide(fks,mod,out=np.zeros_like(fks),where=mod!=0)\n",
    "\n",
    "    return fks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''using cythonized function\n",
    "def features(L_grad,xk,ilum_sat=0.2):\n",
    "    N = xk.shape[0]\n",
    "    Lx,Ly = L_grad\n",
    "    Lmod = np.sqrt(Lx**2+Ly**2)\n",
    "    rho = np.arctan2(Ly,Lx)\n",
    "    \n",
    "    \n",
    "    rho[rho<0]+=2*math.pi\n",
    "\n",
    "    Lmod_patches = get_patches2(Lmod,xk[:,:4],16,16)\n",
    "    rho_patches = get_patches2(rho,xk[:,:4],16,16)\n",
    "   \n",
    "    \n",
    "    rho_patches = xk[:,4][np.newaxis,np.newaxis,:]- rho_patches \n",
    "    rho_patches[rho_patches<0]+=2*math.pi\n",
    "    \n",
    "\n",
    "    Imag = split_tensor(Lmod_patches)#np.moveaxis(Lmod_patches,0,2))\n",
    "    Irho = split_tensor(rho_patches)\n",
    "    \n",
    "    bins = np.arange(0,2*math.pi,2*math.pi/8)\n",
    "    hist_patches = np.reshape(np.digitize(Irho,bins)-1,(16,16,-1))\n",
    "    Imag = Imag.reshape((16,16,-1))\n",
    "    \n",
    "    fk = np.zeros((N,8*16))\n",
    "    for kp in range(N):\n",
    "        fk1=np.empty(0)\n",
    "        sig = split_matrix(cpy_GF.GaussianFilter(16,16,1.5*xk[kp,3]))\n",
    "        \n",
    "        for i in range(16):\n",
    "            sig_ = sig[:,:,i]\n",
    "            contrib = np.zeros(8)\n",
    "            for j in range(16):\n",
    "                contrib[hist_patches[j,i,kp]]+=Imag[j,i,kp]*sig_.flatten()[j]\n",
    "\n",
    "            fk1 = np.append(fk1,contrib)\n",
    "        vec = np.hstack(fk1)\n",
    "        norm = vec/np.linalg.norm(vec)\n",
    "        vec = np.clip(norm,None,ilum_sat)\n",
    "        fk[kp,:] = vec/np.linalg.norm(vec)\n",
    "            \n",
    "\n",
    "            #orient.append(bins[np.argmax(norm)])      \n",
    "            \n",
    "        \n",
    "    return fk\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def SIFT(im,sig=1.6,N=2,s=5,max_sup_window = (3,3),peak_th=0.03,edge_th=10,ilum_sat=0.2,debug=False):\n",
    "    im=im/255.0\n",
    "    im_stack = np.repeat(im[np.newaxis,:,:],s+1,axis=0)\n",
    "    factor=0\n",
    "    pyr=[]\n",
    "    xks=[]\n",
    "    fks=[]\n",
    "    if debug==True: print('Original image size: {}'.format(im_stack.shape))\n",
    "    for i in range(N):    \n",
    "        if debug==True: print('factor: {}'.format(i))\n",
    "\n",
    "        D,L,sigma,L_grad = octave(im_stack,factor=i,sig0=sig,s=s,h=3,w=3)\n",
    "    \n",
    "        xk = np.moveaxis(D[1:-1],0,2)*conv2d_max(D,max_sup_window)\n",
    "\n",
    "        xk = np.argwhere(xk)\n",
    "        if debug==True: print('Initial number of kps: {}'.format(xk.shape[0]))\n",
    "        if debug==True: print('Scale range: {}'.format(np.round(sigma,2)))\n",
    "\n",
    "        xk = build_sig(xk,sigma)\n",
    "\n",
    "        deltas,keep = refine_location_prune(im,D,xk,peak_th,edge_th,debug)\n",
    "        if debug==True: print('Remaining kps after prunning: {}'.format(np.sum(keep)))\n",
    "        xk[:,:3] += deltas\n",
    "        xk = xk[keep,:]\n",
    "        \n",
    "        xk = set_rho(L_grad,xk,h=17,w=17)\n",
    "\n",
    "        fk = features(L_grad,xk,ilum_sat)\n",
    "     \n",
    "        xk[:,:2] = xk[:,:2]*(2**i)\n",
    "        sig*=2\n",
    "        \n",
    "        if debug==True:\n",
    "            plt.imshow(np.squeeze(im),**{\"cmap\":\"gray\"})\n",
    "            plt.scatter(xk[:,1],xk[:,0],s=1,color='red')\n",
    "            plt.show()\n",
    "\n",
    "        xks.append(xk)\n",
    "        fks.append(fk)\n",
    "\n",
    "    xk = np.vstack(xks)\n",
    "    fk = np.vstack(fks) \n",
    "    return xk,fk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_SIFT(im,sig=1.6,N=2,s=5,max_sup_window = (3,3),peak_th=0.03,edge_th=10,ilum_sat=0.2,debug=False):\n",
    "    #im=im/255\n",
    "    im_stack = np.repeat(im[np.newaxis,:,:],s+1,axis=0)\n",
    "    factor=0\n",
    "    pyr=[]\n",
    "    xks=[]\n",
    "    bin_ = {}\n",
    "    if debug==True: print('Original image size: {}'.format(im_stack.shape))\n",
    "    for i in range(N):    \n",
    "        if debug==True: print('factor: {}'.format(i))\n",
    "\n",
    "        D,L,sigma,L_grad = octave(im_stack,factor=i,sig0=sig,s=s,h=3,w=3)\n",
    "    \n",
    "        xk = np.moveaxis(D[1:-1],0,2)*conv2d_max(D,max_sup_window)\n",
    "\n",
    "        xk = np.argwhere(xk)\n",
    "        if debug==True: print('Initial number of kps: {}'.format(xk.shape[0]))\n",
    "        if debug==True: print('Scale range: {}'.format(np.round(sigma,2)))\n",
    "\n",
    "        xk = build_sig(xk,sigma)\n",
    "\n",
    "        deltas,keep = refine_location_prune(im,D,xk,peak_th,edge_th,debug)\n",
    "        if debug==True: print('Remaining kps after prunning: {}'.format(np.sum(keep)))\n",
    "        xk[:,:3] += deltas\n",
    "        xk = xk[keep,:]\n",
    "        \n",
    "        xk = set_rho(L_grad,xk,h=17,w=17)\n",
    "        \n",
    "        bin_[i] = {'xk':xk.copy(),'Lgrad':L_grad}\n",
    "     \n",
    "        xk[:,:2] = xk[:,:2]*(2**i)\n",
    "        sig*=2\n",
    "        \n",
    "        if debug==True:\n",
    "            plt.imshow(np.squeeze(im),**{\"cmap\":\"gray\"})\n",
    "            plt.scatter(xk[:,1],xk[:,0],s=1,color='red')\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        xks.append(xk)\n",
    "\n",
    "    xk = np.vstack(xks)\n",
    "    return xk,bin_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spend: 1.7642896175384521\n",
      "Number of keypoints detected: 2901\n"
     ]
    }
   ],
   "source": [
    "sift1 = SIFT(im='img/house/house0.jpg',Red=2)\n",
    "start = time.time()\n",
    "sift1.get_xks()\n",
    "end = time.time()\n",
    "print('Total time spend: {}'.format(end-start))\n",
    "print('Number of keypoints detected: {}'.format(xk.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spend: 2.704404592514038\n",
      "Number of keypoints detected: 2901\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fks = sift1.get_fks()\n",
    "end = time.time()\n",
    "print('Total time spend: {}'.format(end-start))\n",
    "print('Number of keypoints detected: {}'.format(xk.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tensor(A):\n",
    "    x = (np.tile(np.tile(np.arange(4),16) + np.repeat(np.arange(0,14,4),16),4).reshape((4,-1)).T).astype(int)\n",
    "    y = (np.tile(np.repeat(np.arange(0,14,4),4),4)[:,np.newaxis]+np.arange(4)).astype(int)\n",
    "\n",
    "    k = A.shape[2]\n",
    "\n",
    "    z = (np.repeat(np.zeros((64,4)),k).reshape((64,4,-1)) + np.arange(k)).astype(int)\n",
    "    x = np.repeat(x[:,:,np.newaxis],k,axis=2)\n",
    "    y= np.repeat(y[:,:,np.newaxis],k,axis=2)\n",
    "\n",
    "\n",
    "    return np.dstack(np.split(A[x,y,z],16)).reshape((4,4,16,-1))\n",
    "\n",
    "\n",
    "def split_matrix(A):\n",
    "    x = (np.tile(np.tile(np.arange(4),16) + np.repeat(np.arange(0,14,4),16),4).reshape((4,-1)).T).astype(int)\n",
    "    y = (np.tile(np.repeat(np.arange(0,14,4),4),4)[:,np.newaxis]+np.arange(4)).astype(int)\n",
    "    return np.dstack(np.split(A[x,y],16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduce_stack(stack,k):\n",
    "\n",
    "    N,H0,W0 = stack.shape\n",
    "\n",
    "    H=H0-H0%(2**k)\n",
    "    stack = stack[:,:H,:]\n",
    "    \n",
    "    W=W0-W0%(2**k)\n",
    "    stack = stack[:,:,:W]\n",
    "    \n",
    "    i = np.repeat(np.arange(0,H,2**k)[np.newaxis,:],W//(2**k),axis=0)\n",
    "    j = np.repeat(np.arange(0,W,2**k)[:,np.newaxis],H//(2**k),axis=1)\n",
    "\n",
    "\n",
    "    return np.moveaxis(stack[:,i,j],2,1)\n",
    "\n",
    "def Reduce(im,k):   \n",
    "    for j in range(k):\n",
    "        H,W = im.shape\n",
    "\n",
    "        Dx = np.zeros((int((H+H%2)/2),H))\n",
    "        Dx[np.arange(int((H+H%2)/2)),np.arange(0,H,2)]=1\n",
    "\n",
    "        Dy = np.zeros((int((W+W%2)/2),W))\n",
    "        Dy[np.arange(int((W+W%2)/2)),np.arange(0,W,2)]=1\n",
    "        im = (Dx.dot(im)).dot(Dy.T)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches2(octave,kp,h=9,w=9):\n",
    "\n",
    "    kp = kp.T\n",
    "\n",
    "    h_ = int((h-1)/2)+1\n",
    "    w_ = int((w-1)/2)+1\n",
    "    octave = np.pad(octave,((0,0),(h_,h_),(w_,w_)),'mean')\n",
    "    mypks=kp[:3].astype(int).T\n",
    "\n",
    "    patches=[]\n",
    "    count=0\n",
    "    for i in mypks:\n",
    "\n",
    "        p = octave[i[2],i[0]:i[0]+h,i[1]:i[1]+w]\n",
    "\n",
    "        patches.append(p)\n",
    "        count+=1\n",
    "        if p.shape[0]==0:\n",
    "            print('patch w/ zero shape on kp {}'.format(i))\n",
    "    return np.dstack(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def set_rho(L_grad,xk,h=17,w=17):\n",
    "    set_rho1(L_grad,xk,h=17,w=17)\n",
    "    N = xk.shape[0]\n",
    "    #bins = np.arange(math.pi/36,2*math.pi+math.pi/36,2*math.pi/36)\n",
    "    bins = np.arange(0,2*math.pi,2*math.pi/36)\n",
    "    Lmod_patches,rho_patches = HOG(L_grad,xk,h,w)\n",
    "    hist_patches = np.reshape(np.digitize(rho_patches,bins)-1,(N,-1))\n",
    "    Lmod_patches = Lmod_patches.reshape(N,-1)\n",
    "    rho_patches = rho_patches.reshape(N,-1)\n",
    "\n",
    "\n",
    "    orient = []\n",
    "    for e in range(N):\n",
    "        sig = cpy_GF.GaussianFilter(h,w,1.5*xk[e,3]).flatten()\n",
    "        contrib = np.zeros(h*w)\n",
    "        for i in range(h*w):\n",
    "            contrib[hist_patches[e,i]]+=Lmod_patches[e,i]\n",
    "\n",
    "        if np.linalg.norm(contrib)==0:\n",
    "            orient.append(0)\n",
    "            continue\n",
    "        norm = (sig*contrib/np.linalg.norm(contrib*sig))\n",
    "        if np.sum(norm>0.8)>1:\n",
    "            print('include the kp split on HOG')\n",
    "            orient.append(bins[np.argmax(norm)])\n",
    "        orient.append(bins[np.argmax(norm)])\n",
    "    \n",
    "    return np.vstack((xk.T,orient)).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFT:\n",
    "    def __init__(self,im='img/house/house0.jpg',Red=2):\n",
    "        im = plt.imread(im)\n",
    "        self.im = Reduce(np.mean(im,axis=2),Red)\n",
    "        \n",
    "    def get_xks(self,sig=1.6,N=2,s=5,max_sup_window = (3,3),peak_th=0.03,edge_th=10,ilum_sat=0.2,debug=False):\n",
    "        im=self.im/255\n",
    "        im_stack = np.repeat(im[np.newaxis,:,:],s+1,axis=0)\n",
    "        factor=0\n",
    "        pyr=[]\n",
    "        xks=[]\n",
    "        bin_ = {}\n",
    "        if debug==True: print('Original image size: {}'.format(im_stack.shape))\n",
    "        for i in range(N):    \n",
    "            if debug==True: print('factor: {}'.format(i))\n",
    "\n",
    "            D,L,sigma,L_grad = octave(im_stack,factor=i,sig0=sig,s=s,h=3,w=3)\n",
    "\n",
    "            xk = np.moveaxis(D[1:-1],0,2)*conv2d_max(D,max_sup_window)\n",
    "\n",
    "            xk = np.argwhere(xk)\n",
    "            if debug==True: print('Initial number of kps: {}'.format(xk.shape[0]))\n",
    "            if debug==True: print('Scale range: {}'.format(np.round(sigma,2)))\n",
    "\n",
    "            xk = build_sig(xk,sigma)\n",
    "\n",
    "            deltas,keep = refine_location_prune(im,D,xk,peak_th,edge_th,debug)\n",
    "            if debug==True: print('Remaining kps after prunning: {}'.format(np.sum(keep)))\n",
    "            xk[:,:3] += deltas\n",
    "            xk = xk[keep,:]\n",
    "\n",
    "            xk = set_rho(L_grad,xk,h=17,w=17)\n",
    "\n",
    "            bin_[i] = {'xk':xk.copy(),'Lgrad':L_grad}\n",
    "\n",
    "            xk[:,:2] = xk[:,:2]*(2**i)\n",
    "            sig*=2\n",
    "\n",
    "            if debug==True:\n",
    "                plt.imshow(np.squeeze(im),**{\"cmap\":\"gray\"})\n",
    "                plt.scatter(xk[:,1],xk[:,0],s=1,color='red')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            xks.append(xk)\n",
    "\n",
    "        xk = np.vstack(xks)\n",
    "        self.xk=xk\n",
    "        self.bin_=bin_\n",
    "    \n",
    "    def get_fks(self,ilum_sat=0.8):\n",
    "        fk = []\n",
    "        for i in self.bin_:\n",
    "            fk.append(features(self.bin_[i]['Lgrad'],\n",
    "                          self.bin_[i]['xk'],ilum_sat))\n",
    "        self.fks=np.vstack(fk)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine transformation LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Affine(pairs,num=4):\n",
    "\n",
    "    idx = np.arange(pairs[0].shape[0])\n",
    "\n",
    "    i = np.random.choice(idx,num)\n",
    "    \n",
    "    A = np.zeros((2*num,6))\n",
    "\n",
    "    A[:num,0] = pairs[0][i,0]\n",
    "    A[:num,1] = pairs[0][i,1]\n",
    "    A[:num,4] = np.ones(num)\n",
    "\n",
    "    A[num:,2] = pairs[0][i,0]\n",
    "    A[num:,3] = pairs[0][i,1]\n",
    "    A[num:,5] = np.ones(num)\n",
    "\n",
    "\n",
    "    y = np.zeros(2*num)\n",
    "    y[:num] = pairs[1][i,0]\n",
    "    y[num:] = pairs[1][i,1]\n",
    "    \n",
    "\n",
    "    w = np.linalg.inv(A.T.dot(A)).dot(A.T.dot(y))\n",
    "\n",
    "    return w,affine_error(pairs,w),pairs[0][i],pairs[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_error(pairs,w):\n",
    "\n",
    "    A = np.reshape(w,(2,3))\n",
    "\n",
    "    x0 = np.vstack((pairs[0][:,:2].T,np.ones(pairs[0].shape[0])))\n",
    "\n",
    "    x1_ = A.dot(x0)\n",
    "    \n",
    "\n",
    "    return np.sum((x1_ - pairs[1][:,:2].T)**2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_project(pairs,best_fit,w):\n",
    "\n",
    "    x0 = np.vstack((pairs[0][best_fit,:2].T,np.ones(np.sum(best_fit))))\n",
    "\n",
    "    a,b,e,c,d,f = w\n",
    "    \n",
    "    A = np.array([[a,b,e],[c,d,f]])\n",
    "    \n",
    "    return A.dot(x0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homography LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_A(num, pairs,i):\n",
    "    \n",
    "    A = np.zeros((2*num,9))\n",
    "\n",
    "    A[:num,0] = pairs[0][i,0]\n",
    "    A[:num,1] = pairs[0][i,1]\n",
    "    A[:num,2] = np.ones(num)\n",
    "\n",
    "    A[:num,6] = -1*pairs[1][i,0]*pairs[0][i,0]\n",
    "    A[:num,7] = -1*pairs[1][i,0]*pairs[0][i,1]\n",
    "    A[:num,8] = -1*pairs[1][i,0]\n",
    "\n",
    "\n",
    "    A[num:,3] = pairs[0][i,0]\n",
    "    A[num:,4] = pairs[0][i,1]\n",
    "    A[num:,5] = np.ones(num)\n",
    "\n",
    "    A[num:,6] = -1*pairs[1][i,1]*pairs[0][i,0]\n",
    "    A[num:,7] = -1*pairs[1][i,1]*pairs[0][i,1]\n",
    "    A[num:,8] = -1*pairs[1][i,1]\n",
    "    return A\n",
    "\n",
    "def Homography(pairs,num=4):\n",
    "    idx = np.arange(pairs[0].shape[0])\n",
    "\n",
    "    i = np.random.choice(idx,num)\n",
    "\n",
    "    A = build_A(num,pairs,i)\n",
    "\n",
    "    U,S,V = linalg.svd(A)\n",
    "    \n",
    "    h = V[-1]\n",
    "    \n",
    "    \n",
    "\n",
    "    e = homography_error(pairs,h) \n",
    "\n",
    "    return h,e,pairs[0][i],pairs[1][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def homography_error(pairs,h):\n",
    "\n",
    "    H = np.reshape(h,(3,3))\n",
    "\n",
    "    x0 = np.vstack((pairs[0][:,:2].T,np.ones(pairs[0].shape[0])))\n",
    "\n",
    "    x1_ = H.dot(x0)\n",
    "    \n",
    "    x1_ = np.divide(x1_[:2,:],x1_[2,:],out=np.zeros_like(x1_[:2,:]),\n",
    "                    where=x1_[2,:]!=0)\n",
    "    \n",
    "    return np.sum((x1_ - pairs[1][:,:2].T)**2,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching: Nearest Neighboor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''Using cythonized function instead\n",
    "def npndarray_nearest_neighboor(fk1,xk1,fk2,xk2,crt=0.8):\n",
    "    \n",
    "    fk=fk1\n",
    "    count=0\n",
    "    idx2 = np.empty(0,dtype=np.int)\n",
    "    idx1= np.empty(0,dtype=np.int)\n",
    "    phi_ = np.empty(0,dtype=np.int)\n",
    "    \n",
    "    for i in range(fk.shape[0]):\n",
    "        v = fk[i]\n",
    "        d = np.sum((fk2-v)**2,axis=1)\n",
    "\n",
    "        f1,f2 = np.argsort(d)[:2]\n",
    "        if np.sum((v - fk2[f2])**2)==0:\n",
    "            continue\n",
    "\n",
    "        phi = np.sum((v - fk2[f1])**2)/np.sum((v - fk2[f2])**2)\n",
    "        \n",
    "        if phi<crt:\n",
    "            idx2 = np.append(idx2,f1)\n",
    "            idx1 = np.append(idx1,i)\n",
    "            phi_= np.append(phi_,[phi])\n",
    "\n",
    "    pairs = (xk1[idx1,:],xk2[idx2])\n",
    "\n",
    "    idx = np.argsort(phi_)\n",
    "    return pairs,idx\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sample Consensus - RANSAC\n",
    "\n",
    "Likelihood that S trials will fail:\n",
    "$$1-P=(1-p^k)^s$$\n",
    "\n",
    "For a given probability of having inliers, the required minimum number of trials S is:\n",
    "$$S = \\frac{log(1-P)}{log(1-p^k)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "p - probability of being an inlier\n",
    "k - number of samples\n",
    "S - number of required trials\n",
    "'''\n",
    "def RANSAC(im1,im2,pairs,min_pts=4,p=0.1,P=.99,th=5,type_='affine'):\n",
    "    \n",
    "    S = np.round(np.log(1-P)/(np.log(1-p**min_pts))).astype(int)\n",
    "    num_pts = pairs[0].shape[0]\n",
    "    \n",
    "    best_fit=0\n",
    "    \n",
    "    for i in range(S):\n",
    "        try:\n",
    "            if type_=='affine':\n",
    "                w,e,x1,x2 = Affine(pairs,min_pts)\n",
    "            else:\n",
    "                w,e,x1,x2 = Homography(pairs,min_pts)\n",
    "            \n",
    "            inliers = np.sum(e<th**2)\n",
    "            \n",
    "            if inliers>=best_fit:\n",
    "                best_w = w\n",
    "                best_e = np.sum(e)\n",
    "                best_x1 = x1\n",
    "                best_x2 = x2\n",
    "                idx = e<th**2\n",
    "                best_fit = inliers\n",
    "                p = inliers/num_pts\n",
    "                S = np.round(np.log(1-P)/(np.log(1-p**min_pts))).astype(int)\n",
    " \n",
    "        except:     \n",
    "            continue\n",
    "\n",
    "    try:\n",
    "            \n",
    "        if type_=='affine':\n",
    "            best_w,e,x1,x2 = Affine((pairs[0][idx],pairs[1][idx]),len(pairs[0][idx]))\n",
    "        else:\n",
    "            best_w,e,x1,x2 = Homography((pairs[0][idx],pairs[1][idx]),len(pairs[0][idx]))\n",
    "\n",
    "        best_x1 = x1\n",
    "        best_x2 = x2\n",
    "\n",
    "\n",
    "        print(\"Ransac affine/homography best matches:\")\n",
    "       \n",
    "        plt.imshow(im1,**{'cmap':'gray'})\n",
    "\n",
    "        plt.scatter(best_x1[:,1],best_x1[:,0],c='red',s=10)\n",
    "\n",
    "        for i in range(len(pairs[0][idx])):\n",
    "            plt.text(best_x1[i,1],best_x1[i,0],str(i),withdash=False,**{'color':'red'})\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(im2,**{'cmap':'gray'})\n",
    "        plt.scatter(best_x2[:,1],best_x2[:,0],c='red',s=10)\n",
    "\n",
    "\n",
    "        for i in range(len(pairs[0][idx])):\n",
    "            plt.text(best_x2[i,1],best_x2[i,0],str(i),withdash=False,**{'color':'red'})\n",
    "\n",
    "        plt.show()\n",
    "        print(\"RANSAC number of inlers: {}\".format(best_fit))\n",
    "    except:\n",
    "        print(\"didn't converge\")\n",
    "    \n",
    "    if type_=='affine':\n",
    "        H = np.reshape(best_w,(2,3))\n",
    "    else:\n",
    "        H = np.reshape(best_w,(3,3))\n",
    "        \n",
    "    return H,idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main()\n",
    "1. Find scale invariant features\n",
    "2. build SIFT descriptor\n",
    "3. Fit affine/homography transformation using RANSAC to deal with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun\n",
    "def match(img1_,img2_,N=3,s=5,sig=1.6,max_sup_window = (5,5),type_='affine',peak_th=0.05,ilum_sat=0.2,edge_th=10,num='max',min_pts=4,Red=0,nn_plot=False,debug=False,crt=0.8,RANSAC_th=100,RANSAC_p=0.2):\n",
    "   \n",
    "    im1 = plt.imread(img1_)\n",
    "    im1 = Reduce(np.mean(im1,axis=2),Red)\n",
    "    xk1,fk1 = SIFT(im1,N=N,s=s,sig=sig,max_sup_window = (5,5),ilum_sat=ilum_sat,peak_th=peak_th,edge_th=edge_th,debug=debug)\n",
    "    \n",
    "    \n",
    "    im2 = plt.imread(img2_)\n",
    "    im2 = np.squeeze(Reduce_stack(np.mean(im2,axis=2)[np.newaxis,:,:],Red))\n",
    "    xk2,fk2 = SIFT(im2,N=N,s=s,sig=sig,max_sup_window = (5,5),ilum_sat=ilum_sat,peak_th=peak_th,edge_th=edge_th,debug=debug)\n",
    "\n",
    "    pairs,idx = cpy_nn.nearest_neighboor(fk1,xk1,fk2,xk2,crt)\n",
    "\n",
    "    \n",
    "    \n",
    "    if num=='max':\n",
    "        num = len(idx)\n",
    "\n",
    "    if nn_plot==True:\n",
    "        print(\"Nearest Neighboor matches: {} pts\".format(pairs[0].shape[0]))\n",
    "        plt.imshow(im1,**{'cmap':'gray'})\n",
    "\n",
    "        plt.scatter(pairs[0][:,1][idx[:num]],pairs[0][:,0][idx[:num]],c='red',s=1)\n",
    "        #for i in range(num):\n",
    "        #    plt.text(pairs[0][:,1][idx[i]],pairs[0][:,0][idx[i]],str(i),withdash=False,**{'color':'red'})\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(im2,**{'cmap':'gray'})\n",
    "        plt.scatter(pairs[1][:,1][idx[:num]],pairs[1][:,0][idx[:num]],c='red',s=1)\n",
    "        #for i in range(num):\n",
    "        #    plt.text(pairs[1][:,1][idx[i]],pairs[1][:,0][idx[i]],str(i),withdash=False,**{'color':'red'})\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    if RANSAC_th !=None:\n",
    "        H,idx = RANSAC(im1,im2,pairs,min_pts,type_=type_,P=.98,th=RANSAC_th,p=RANSAC_p)\n",
    "\n",
    "        pairs = (pairs[0][idx],pairs[1][idx])\n",
    "        return fk1,fk2,xk1,xk2,pairs,H\n",
    "\n",
    "    \n",
    "    return fk1,fk2,xk1,xk2,pairs,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "fk1,fk2,xk1,xk2,pairs,H0= match(img1_='img/house/house0.jpg',\n",
    "                             img2_='img/house/house1.jpg',\n",
    "                             N=3,s=5,sig=2,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=2.5,RANSAC_p=0.15)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "fk1,fk2,xk1,xk2,pairs,H0= match(img1_='img/house/house0.jpg',\n",
    "                             img2_='img/house/house1.jpg',\n",
    "                             N=1,s=5,sig=2,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=2.5,RANSAC_p=0.15)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp\n",
    "image = np.mean(plt.imread('img/house/house1.jpg'),axis=2)\n",
    "plt.imshow(warp(image, np.linalg.inv(H0)),**{'cmap':'gray'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,H= match(img1_='img/pepsi1.jpg',\n",
    "                             img2_='img/pepsi2.jpg',\n",
    "                               max_sup_window = (3,3),\n",
    "                             N=2,s=5,sig=1.6,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=5)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,H1= match(img1_='img/house/house0.jpg',\n",
    "                             img2_='img/house/house8.jpg',\n",
    "                             N=2,s=5,sig=1.6,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=5\n",
    "                               ,RANSAC_p=0.15)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp,ProjectiveTransform\n",
    "H = ProjectiveTransform(H1)\n",
    "image = np.mean(plt.imread('img/house/house8.jpg'),axis=2)\n",
    "plt.imshow(warp(image, H),**{'cmap':'gray'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,H2= match(img1_='img/house/house8.jpg',\n",
    "                             img2_='img/house/house23.jpg',\n",
    "                             N=3,s=5,sig=1.6,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.5,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=5)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp,ProjectiveTransform\n",
    "H = ProjectiveTransform(H2)\n",
    "image = np.mean(plt.imread('img/house/house23.jpg'),axis=2)\n",
    "plt.imshow(warp(image, H),**{'cmap':'gray'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,H3= match(img1_='img/house/house23.jpg',\n",
    "                             img2_='img/house/house22.jpg',\n",
    "                             N=1,s=5,sig=2,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num=20,\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=2.5,RANSAC_p=0.15)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp,ProjectiveTransform\n",
    "H = ProjectiveTransform(H3)\n",
    "image = np.mean(plt.imread('img/house/house22.jpg'),axis=2)\n",
    "plt.imshow(warp(image, H),**{'cmap':'gray'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,H4= match(img1_='img/house/house22.jpg',\n",
    "                             img2_='img/house/house18.jpg',\n",
    "                             N=1,s=5,sig=2,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num=20,\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=2.5,RANSAC_p=0.15)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp,ProjectiveTransform\n",
    "H = ProjectiveTransform(H4)\n",
    "image = np.mean(plt.imread('img/house/house18.jpg'),axis=2)\n",
    "plt.imshow(warp(image, H),**{'cmap':'gray'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,H5= match(img1_='img/house/house18.jpg',\n",
    "                             img2_='img/house/house16.jpg',\n",
    "                             N=3,s=5,sig=1.6,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=5)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp,ProjectiveTransform\n",
    "H = ProjectiveTransform(H5)\n",
    "image = np.mean(plt.imread('img/house/house16.jpg'),axis=2)\n",
    "plt.imshow(warp(image, H),**{'cmap':'gray'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,_= match(img1_='img/uoft4.jpg',\n",
    "                             img2_='img/uoft6.jpg',\n",
    "                             N=3,s=5,sig=1.6,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=4,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,RANSAC_th=5,RANSAC_p=0.1)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "start = time.time()\n",
    "\n",
    "fk1,fk2,xk1,xk2,pairs,_= match(img1_='img/book_temp.jpg',\n",
    "                             img2_='img/book_match.jpg',\n",
    "                             N=4,s=3,sig=1,\n",
    "                             peak_th=0.03,edge_th=10,\n",
    "                             ilum_sat=0.2,num='max',\n",
    "                             Red=2,crt=0.8,\n",
    "                             type_='homography',\n",
    "                             min_pts=4,\n",
    "                             nn_plot=False,debug=False,\n",
    "                            RANSAC_th=2.5,RANSAC_p=0.1)\n",
    "end = time.time()\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General summary:\n",
    "Planar/Distinctive objects: \n",
    "Scale Invariant interest points, SIFT descriptor, matching with nn + affine/homography\n",
    "\n",
    "Panorama Stiching:\n",
    "Scale Invariant interest points, SIFT descriptor, matching with nn + homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
